{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "dataset link : [https://drive.google.com/file/d/1X4Hcj72NK7J2JYvgjICFj0R1XwUq1w0a/view](https://)"
      ],
      "metadata": {
        "id": "hAbvY5Y9r5Rw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6YMMVbEda3vI"
      },
      "outputs": [],
      "source": [
        "path = \"/content/100_Unique_QA_Dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GZONe2Y3bgaY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "BnLJg3Jibitc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lvlcdK2NbkfE",
        "outputId": "5113d6f7-38c5-48d7-d799-59a7369d1fbd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a97f0c2-3774-4c83-85e1-bdc0796f0167\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a97f0c2-3774-4c83-85e1-bdc0796f0167')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a97f0c2-3774-4c83-85e1-bdc0796f0167 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a97f0c2-3774-4c83-85e1-bdc0796f0167');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(row):\n",
        "  row = row.lower()\n",
        "  row = row.replace(\"?\",\" \")\n",
        "  row = row.replace(\"'\",\" \")\n",
        "  return row.split()"
      ],
      "metadata": {
        "id": "yuTvMzdGblVf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(\"what is the capital of france?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSXpJNEUcL7h",
        "outputId": "e5aac52f-0c09-4e69-d1ca-0842ceae4aa8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary\n",
        "vocab = {\"<unk>\":0}"
      ],
      "metadata": {
        "id": "5b58sSAuce5J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocabulary(row):\n",
        "  tokenized_question = tokenize(row[\"question\"])\n",
        "  tokenized_answer = tokenize(row[\"answer\"])\n",
        "  sentence = tokenized_question + tokenized_answer\n",
        "  for token in sentence:\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)"
      ],
      "metadata": {
        "id": "wGVanRlCcPjp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocabulary,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "collapsed": true,
        "id": "G21si8Jmc-F8",
        "outputId": "60451aec-4606-4c14-c8a1-133e5b8d24e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pun2ryWdDSl",
        "outputId": "727974c8-824d-4c1f-f89a-4cf46080c1a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G3bVkl04dIBJ",
        "outputId": "43d005aa-442b-4845-af4a-24d01c79a4c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " 'to': 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " 'mockingbird': 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " '1984': 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299,792,458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " 'starry': 130,\n",
              " 'night': 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'step': 143,\n",
              " 'moon': 144,\n",
              " 'armstrong': 145,\n",
              " 'main': 146,\n",
              " 'ingredient': 147,\n",
              " 'guacamole': 148,\n",
              " 'avocado': 149,\n",
              " 'sides': 150,\n",
              " 'does': 151,\n",
              " 'hexagon': 152,\n",
              " 'have': 153,\n",
              " '6': 154,\n",
              " 'china': 155,\n",
              " 'yuan': 156,\n",
              " 'pride': 157,\n",
              " 'and': 158,\n",
              " 'prejudice': 159,\n",
              " 'jane-austen': 160,\n",
              " 'iron': 161,\n",
              " 'fe': 162,\n",
              " 'hardest': 163,\n",
              " 'natural': 164,\n",
              " 'substance': 165,\n",
              " 'diamond': 166,\n",
              " 'continent': 167,\n",
              " 'by': 168,\n",
              " 'area': 169,\n",
              " 'asia': 170,\n",
              " 'president': 171,\n",
              " 'states': 172,\n",
              " 'george-washington': 173,\n",
              " 'bird': 174,\n",
              " 'its': 175,\n",
              " 'ability': 176,\n",
              " 'mimic': 177,\n",
              " 'sounds': 178,\n",
              " 'parrot': 179,\n",
              " 'longest-running': 180,\n",
              " 'animated': 181,\n",
              " 'tv': 182,\n",
              " 'show': 183,\n",
              " 'simpsons': 184,\n",
              " 'vaticancity': 185,\n",
              " 'most': 186,\n",
              " 'moons': 187,\n",
              " 'saturn': 188,\n",
              " 'romeo': 189,\n",
              " 'juliet': 190,\n",
              " 'shakespeare': 191,\n",
              " 's': 192,\n",
              " 'atmosphere': 193,\n",
              " 'nitrogen': 194,\n",
              " 'bones': 195,\n",
              " 'adult': 196,\n",
              " 'human': 197,\n",
              " 'body': 198,\n",
              " '206': 199,\n",
              " 'metal': 200,\n",
              " 'liquid': 201,\n",
              " 'at': 202,\n",
              " 'room': 203,\n",
              " 'temperature': 204,\n",
              " 'mercury': 205,\n",
              " 'russia': 206,\n",
              " 'moscow': 207,\n",
              " 'electricity': 208,\n",
              " 'benjamin-franklin': 209,\n",
              " 'second-largest': 210,\n",
              " 'land': 211,\n",
              " 'color': 212,\n",
              " 'ripe': 213,\n",
              " 'banana': 214,\n",
              " 'yellow': 215,\n",
              " 'month': 216,\n",
              " '28': 217,\n",
              " 'days': 218,\n",
              " 'common': 219,\n",
              " 'february': 220,\n",
              " 'study': 221,\n",
              " 'living': 222,\n",
              " 'organisms': 223,\n",
              " 'called': 224,\n",
              " 'biology': 225,\n",
              " 'home': 226,\n",
              " 'great': 227,\n",
              " 'wall': 228,\n",
              " 'bees': 229,\n",
              " 'collect': 230,\n",
              " 'from': 231,\n",
              " 'flowers': 232,\n",
              " 'nectar': 233,\n",
              " 'opposite': 234,\n",
              " 'day': 235,\n",
              " 'south': 236,\n",
              " 'korea': 237,\n",
              " 'seoul': 238,\n",
              " 'bulb': 239,\n",
              " 'edison': 240,\n",
              " 'humans': 241,\n",
              " 'breathe': 242,\n",
              " 'survival': 243,\n",
              " 'oxygen': 244,\n",
              " '144': 245,\n",
              " '12': 246,\n",
              " 'pyramids': 247,\n",
              " 'giza': 248,\n",
              " 'egypt': 249,\n",
              " 'sea': 250,\n",
              " 'creature': 251,\n",
              " 'eight': 252,\n",
              " 'arms': 253,\n",
              " 'octopus': 254,\n",
              " 'holiday': 255,\n",
              " 'celebrated': 256,\n",
              " 'december': 257,\n",
              " '25': 258,\n",
              " 'christmas': 259,\n",
              " 'yen': 260,\n",
              " 'legs': 261,\n",
              " 'spider': 262,\n",
              " 'sport': 263,\n",
              " 'uses': 264,\n",
              " 'net,': 265,\n",
              " 'ball,': 266,\n",
              " 'hoop': 267,\n",
              " 'basketball': 268,\n",
              " 'kangaroos': 269,\n",
              " 'female': 270,\n",
              " 'minister': 271,\n",
              " 'uk': 272,\n",
              " 'margaretthatcher': 273,\n",
              " 'fastest': 274,\n",
              " 'animal': 275,\n",
              " 'cheetah': 276,\n",
              " 'periodic': 277,\n",
              " 'table': 278,\n",
              " 'spain': 279,\n",
              " 'madrid': 280,\n",
              " 'closest': 281,\n",
              " 'sun': 282,\n",
              " 'father': 283,\n",
              " 'computers': 284,\n",
              " 'charlesbabbage': 285,\n",
              " 'mexico': 286,\n",
              " 'mexicocity': 287,\n",
              " 'colors': 288,\n",
              " 'rainbow': 289,\n",
              " 'musical': 290,\n",
              " 'instrument': 291,\n",
              " 'black': 292,\n",
              " 'white': 293,\n",
              " 'keys': 294,\n",
              " 'piano': 295,\n",
              " 'americas': 296,\n",
              " '1492': 297,\n",
              " 'christophercolumbus': 298,\n",
              " 'disney': 299,\n",
              " 'character': 300,\n",
              " 'long': 301,\n",
              " 'nose': 302,\n",
              " 'grows': 303,\n",
              " 'it': 304,\n",
              " 'when': 305,\n",
              " 'lying': 306,\n",
              " 'pinocchio': 307,\n",
              " 'directed': 308,\n",
              " 'movie': 309,\n",
              " 'titanic': 310,\n",
              " 'jamescameron': 311,\n",
              " 'superhero': 312,\n",
              " 'also': 313,\n",
              " 'dark': 314,\n",
              " 'knight': 315,\n",
              " 'batman': 316,\n",
              " 'brasilia': 317,\n",
              " 'fruit': 318,\n",
              " 'king': 319,\n",
              " 'fruits': 320,\n",
              " 'mango': 321,\n",
              " 'eiffel': 322,\n",
              " 'tower': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_index(row,vocab):\n",
        "  index_list = []\n",
        "  for token in tokenize(row):\n",
        "    if token in vocab:\n",
        "      index_list.append(vocab[token])\n",
        "    else:\n",
        "      index_list.append(vocab['<unk>'])\n",
        "  return index_list"
      ],
      "metadata": {
        "id": "LvH83lRJdIzD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_index(\"what is capital of france?\",vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZK2a_vOdyrm",
        "outputId": "f3d32dde-9f5f-40f6-adca-52d176af9820"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 4, 5, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "NRIwrxm6eELq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(self,df,vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "  def __getitem__(self,index):\n",
        "    question = tokenize_index(self.df.iloc[index][\"question\"],vocab)\n",
        "    answer = tokenize_index(self.df.iloc[index][\"answer\"],vocab)\n",
        "    return torch.tensor(question),torch.tensor(answer)"
      ],
      "metadata": {
        "id": "GFgtP5vxeqTq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df,vocab)"
      ],
      "metadata": {
        "id": "MfIznwhvffNc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIK0fvmZfjxH",
        "outputId": "b7efd1e4-299e-49a5-f0ed-1dea0a5b1e6d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mix49t3Wfk3a",
        "outputId": "1dfc3f40-810f-43e3-9d43-d8eb0ef6fd2c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  2,  3,  4,  5, 53]), tensor([54]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset,batch_size=1,shuffle=True)"
      ],
      "metadata": {
        "id": "ti0E7zLkfm7Q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50,hidden_size=64,batch_first=True)\n",
        "    self.linear = nn.Linear(64,vocab_size)\n",
        "  def forward(self,x):\n",
        "    x = self.embedding(x)\n",
        "    hidden,final = self.rnn(x)\n",
        "    return self.linear(final.squeeze(0))"
      ],
      "metadata": {
        "id": "ighfI0QqfxP2"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = model(len(vocab))"
      ],
      "metadata": {
        "id": "odNBvVbwhW-h"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model(dataloader[0])"
      ],
      "metadata": {
        "id": "4gMj3kDNhdfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in dataloader:\n",
        "  print(x.shape,y.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktOhCTVui-Q3",
        "outputId": "ae4fdef1-b706-4440-851e-5754a9bdfd9f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 9]) torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(324, embedding_dim=50)\n",
        "y = nn.RNN(50, 64,batch_first=True) # to get that the final(d) as only the last occurance\n",
        "z = nn.Linear(64, 324)\n",
        "\n",
        "a = dataset[0][0].reshape(1,6)\n",
        "print(\"shape of a:\", a.shape)\n",
        "b = x(a)\n",
        "print(\"shape of b:\", b.shape)\n",
        "c, d = y(b)\n",
        "print(\"shape of c:\", c.shape)\n",
        "print(\"shape of d:\", d.shape)\n",
        "\n",
        "e = z(d.squeeze(0))\n",
        "\n",
        "print(\"shape of e:\", e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdntLhbGi_lN",
        "outputId": "356d4cf0-9fae-43ca-c4fe-1636c8ae0f4b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a: torch.Size([1, 6])\n",
            "shape of b: torch.Size([1, 6, 50])\n",
            "shape of c: torch.Size([1, 6, 64])\n",
            "shape of d: torch.Size([1, 1, 64])\n",
            "shape of e: torch.Size([1, 324])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.shape,d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnsy5qKljTj1",
        "outputId": "a21c747d-03d1-4ab3-c56d-d8d8dac46248"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 6, 64]), torch.Size([1, 1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c,d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FzlcpicPjdz2",
        "outputId": "8554b824-58c3-4443-ebef-c66b9bd77c36"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 6.3264e-01, -3.5769e-01, -4.2828e-01,  1.5967e-01,  1.1467e-01,\n",
              "            4.2389e-01,  2.6980e-01, -1.9390e-01,  2.6303e-01,  2.6533e-01,\n",
              "           -2.9741e-01, -4.7098e-01,  1.6072e-01, -6.0927e-01, -5.2474e-04,\n",
              "            3.3287e-01,  4.9862e-01, -3.0195e-01, -1.7806e-01, -2.1905e-01,\n",
              "            4.8770e-01, -3.6224e-01, -1.1149e-01,  3.4531e-01,  7.6989e-01,\n",
              "            3.9448e-01,  2.9424e-01,  6.5128e-01,  4.3278e-01,  4.3293e-01,\n",
              "           -7.4180e-02, -4.3649e-01, -2.1862e-02, -3.6504e-01, -4.4899e-02,\n",
              "           -6.4405e-01,  1.8321e-01,  2.7709e-02, -6.7488e-01, -7.7164e-02,\n",
              "           -7.5402e-01, -3.5074e-02, -2.1957e-01,  3.9544e-01, -1.6429e-02,\n",
              "           -5.0874e-01, -5.0584e-01,  2.6234e-01, -5.7353e-01, -4.2865e-01,\n",
              "           -5.9423e-02, -6.1964e-02,  4.5222e-01, -2.6996e-02,  5.3350e-01,\n",
              "           -1.9045e-01,  4.1853e-01,  7.6755e-01, -1.7429e-01,  3.9937e-01,\n",
              "           -3.8475e-01, -3.9095e-01,  1.7220e-02,  7.1989e-01],\n",
              "          [ 1.2430e-01,  4.8865e-01, -2.6883e-01, -6.8376e-01,  3.3374e-01,\n",
              "            2.0829e-01,  1.1347e-01, -6.8940e-03, -4.2067e-01,  2.5202e-01,\n",
              "            6.1726e-01, -2.9367e-01,  3.9130e-01,  9.5482e-02,  2.5574e-01,\n",
              "            6.2199e-01,  3.2625e-01, -2.5142e-01, -1.7385e-01, -3.7267e-01,\n",
              "            1.6457e-01,  2.0909e-01, -6.5915e-01, -9.0793e-02, -5.0066e-01,\n",
              "           -8.7991e-01, -4.1695e-01,  6.7772e-01, -2.9645e-01,  1.5160e-01,\n",
              "            7.9355e-01,  3.4093e-01, -1.9291e-01,  5.9409e-01,  4.1140e-01,\n",
              "            3.6692e-01,  1.4925e-01,  2.0790e-01, -6.2106e-01,  3.4519e-01,\n",
              "            4.1739e-02, -2.2058e-01, -1.0368e-01, -3.0407e-01,  3.6336e-01,\n",
              "           -4.6860e-01, -7.8362e-01,  1.2657e-01, -5.8185e-01, -6.7003e-01,\n",
              "            3.6787e-01, -4.5724e-01,  3.4965e-01, -5.0211e-01,  2.3141e-02,\n",
              "           -6.2093e-01, -2.5295e-01,  2.9687e-01,  2.1525e-01, -2.9319e-01,\n",
              "            1.8893e-01, -9.4244e-02,  1.9834e-01, -1.2106e-01],\n",
              "          [ 6.3600e-01,  2.7254e-01,  2.3612e-01, -3.7480e-01,  5.7092e-01,\n",
              "            1.8725e-01, -5.6607e-01,  2.5558e-01,  2.1338e-01, -1.2612e-01,\n",
              "            3.7456e-01,  5.2077e-01, -2.8436e-01,  6.3504e-01, -4.3056e-01,\n",
              "           -4.1938e-01,  2.4488e-01, -5.7959e-01, -4.0901e-01, -5.5730e-01,\n",
              "           -2.4720e-01, -6.5712e-02,  1.4978e-01,  6.1147e-03,  1.4747e-01,\n",
              "           -6.6988e-01, -1.5685e-01, -4.8798e-01,  9.1829e-01,  6.9405e-01,\n",
              "           -1.9722e-01,  4.0579e-01, -4.2547e-01,  8.9148e-01, -2.5415e-01,\n",
              "           -7.2211e-01,  4.0651e-01, -7.1486e-01, -5.9330e-01, -3.8885e-01,\n",
              "            2.5867e-01,  5.7370e-01, -4.6121e-01, -6.2939e-02,  1.3505e-01,\n",
              "            7.8178e-01,  5.4861e-01,  1.8056e-01, -3.8787e-01, -4.8171e-01,\n",
              "           -7.5321e-01, -2.9692e-01,  6.2537e-01, -4.5911e-01, -1.3954e-01,\n",
              "            2.9683e-01, -4.4693e-02,  4.5328e-01, -1.1139e-01, -1.2572e-01,\n",
              "           -6.0824e-01,  9.3507e-02, -6.6097e-01, -1.2607e-01],\n",
              "          [ 3.3537e-02, -7.5707e-01,  5.2220e-01, -7.0504e-01,  1.7001e-01,\n",
              "            2.4284e-01,  1.5478e-01,  2.1987e-01,  5.7595e-01, -1.1033e-01,\n",
              "            6.7225e-01,  7.9288e-01,  6.0128e-01,  5.5822e-01,  5.6386e-01,\n",
              "           -8.2495e-01,  1.4716e-01,  3.7739e-01, -1.5885e-01, -1.2481e-01,\n",
              "            3.3200e-01,  3.7009e-01, -3.0904e-01,  3.6928e-01, -8.6816e-01,\n",
              "           -4.9819e-01, -8.8962e-01, -2.8001e-01, -8.2022e-01, -7.8320e-01,\n",
              "           -4.9819e-01, -5.4571e-01,  2.6215e-01,  2.0207e-01, -7.4200e-01,\n",
              "           -8.0090e-01, -6.5300e-01,  2.7418e-01,  3.2816e-01,  6.8172e-01,\n",
              "            8.0546e-01, -1.9160e-01, -5.8774e-01,  1.9072e-01,  2.1842e-01,\n",
              "            3.0676e-01, -3.9244e-02, -2.2500e-01, -6.0101e-01,  8.3084e-02,\n",
              "           -9.0457e-02,  7.1872e-01,  6.1307e-01,  5.6541e-01, -9.3508e-01,\n",
              "            2.3839e-01, -3.7127e-01, -1.7119e-01, -3.9117e-01, -1.2411e-01,\n",
              "            7.2794e-01, -5.6463e-01,  5.6725e-01, -4.2930e-01],\n",
              "          [ 6.6345e-01, -5.9575e-01,  4.5008e-01, -7.7678e-01,  3.4923e-01,\n",
              "           -2.9224e-01, -4.3936e-01, -4.7463e-01,  3.0975e-01,  1.3971e-02,\n",
              "           -9.3521e-02,  3.3762e-01,  1.5537e-01, -1.2753e-01, -9.6664e-02,\n",
              "            5.3680e-01,  5.0983e-01, -6.7200e-01,  2.4081e-01, -7.0771e-01,\n",
              "            2.1311e-01, -2.6145e-01,  8.9169e-01, -1.0367e-01, -6.1935e-01,\n",
              "            3.8532e-01,  5.1536e-01, -8.0686e-02, -3.1852e-01, -1.2464e-01,\n",
              "           -7.5977e-01,  7.6815e-01, -2.9580e-01,  3.5721e-02, -5.6046e-01,\n",
              "            5.9845e-01,  5.6036e-01,  5.4492e-01, -8.5263e-01,  2.8530e-01,\n",
              "            3.3213e-01, -5.9678e-01,  8.5361e-02, -1.4534e-01,  3.7804e-01,\n",
              "           -2.9570e-01, -7.9543e-01,  8.0857e-01,  1.5301e-01, -4.7731e-01,\n",
              "            8.0709e-02,  4.1594e-01,  6.8530e-01, -6.0481e-01,  1.4772e-01,\n",
              "            3.4444e-01,  5.8134e-01, -4.0574e-01,  7.7246e-01, -4.9112e-01,\n",
              "           -5.5123e-01, -4.8139e-01, -2.4885e-01, -6.1322e-02],\n",
              "          [ 1.9757e-01,  1.8476e-01,  1.9200e-01,  1.2384e-01, -9.0885e-02,\n",
              "           -5.9621e-01, -8.0326e-01,  4.1703e-02,  7.0498e-01, -3.9300e-01,\n",
              "            5.1212e-01, -6.1887e-01,  3.3212e-01, -8.0177e-01, -3.0863e-01,\n",
              "           -7.1418e-01, -1.1118e-01,  1.7016e-01,  2.8476e-01,  3.8930e-01,\n",
              "           -3.9968e-01, -2.6147e-01, -3.9198e-02,  1.9070e-01,  6.9197e-02,\n",
              "           -5.5846e-01,  6.0345e-01, -4.5695e-01,  1.9600e-01, -3.4400e-01,\n",
              "           -2.2088e-01, -2.6564e-01, -4.5705e-01,  3.6764e-01, -5.8678e-01,\n",
              "           -2.4802e-01, -5.6501e-01, -5.1339e-01, -8.8130e-01, -4.2909e-01,\n",
              "            8.1823e-02, -4.7825e-01, -1.5096e-01,  3.2911e-01, -1.5001e-02,\n",
              "            7.6082e-01,  8.0455e-01, -9.1063e-02, -9.1787e-01,  4.7653e-01,\n",
              "            5.3626e-01, -6.1358e-01, -1.4629e-01, -2.1111e-01,  5.3393e-01,\n",
              "           -2.1697e-01, -1.5934e-01, -8.4988e-01, -6.5994e-01,  2.9663e-01,\n",
              "            5.1108e-01,  7.3918e-01, -1.3954e-01,  7.3547e-01]]],\n",
              "        grad_fn=<TransposeBackward1>),\n",
              " tensor([[[ 0.1976,  0.1848,  0.1920,  0.1238, -0.0909, -0.5962, -0.8033,\n",
              "            0.0417,  0.7050, -0.3930,  0.5121, -0.6189,  0.3321, -0.8018,\n",
              "           -0.3086, -0.7142, -0.1112,  0.1702,  0.2848,  0.3893, -0.3997,\n",
              "           -0.2615, -0.0392,  0.1907,  0.0692, -0.5585,  0.6035, -0.4570,\n",
              "            0.1960, -0.3440, -0.2209, -0.2656, -0.4570,  0.3676, -0.5868,\n",
              "           -0.2480, -0.5650, -0.5134, -0.8813, -0.4291,  0.0818, -0.4783,\n",
              "           -0.1510,  0.3291, -0.0150,  0.7608,  0.8046, -0.0911, -0.9179,\n",
              "            0.4765,  0.5363, -0.6136, -0.1463, -0.2111,  0.5339, -0.2170,\n",
              "           -0.1593, -0.8499, -0.6599,  0.2966,  0.5111,  0.7392, -0.1395,\n",
              "            0.7355]]], grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e.squeeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k978waxykuHF",
        "outputId": "43f844b8-fb51-4289-ce70-40d893dfc1f8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7.0501e-02, -1.4555e-01, -1.6593e-01,  8.7636e-02, -1.5836e-01,\n",
              "         -3.2300e-02, -5.0766e-01,  9.6510e-02,  5.0797e-01, -5.8258e-01,\n",
              "          1.8804e-01,  1.2873e-01, -6.3309e-02, -7.5379e-02, -3.4963e-01,\n",
              "          3.8947e-01, -2.2313e-01,  3.9108e-02, -8.3202e-02,  2.0071e-01,\n",
              "          2.9850e-01, -4.8496e-02,  3.0473e-01, -2.8086e-01,  5.7007e-02,\n",
              "          5.1580e-01,  4.7157e-01,  2.8018e-01, -3.8047e-01,  1.6524e-01,\n",
              "         -1.6551e-01, -1.2602e-01,  9.6752e-02,  1.5783e-01,  2.7570e-01,\n",
              "         -2.1586e-01, -3.2147e-02, -1.1390e-01, -2.7417e-01,  2.5986e-02,\n",
              "          1.2590e-01, -3.1699e-01, -1.4163e-01, -3.0561e-01, -1.1990e-01,\n",
              "          1.0782e-01, -1.4830e-01, -4.3994e-04,  1.0184e-01, -5.2345e-02,\n",
              "          1.3092e-01, -7.1893e-02,  1.6092e-02,  2.8581e-01,  1.6281e-01,\n",
              "         -8.6215e-02,  2.7909e-01,  2.7870e-01,  5.0636e-02,  1.1029e-01,\n",
              "         -3.2752e-02, -2.9885e-01, -4.9913e-01, -2.6338e-01, -2.9730e-03,\n",
              "         -7.1681e-01, -2.0596e-01,  1.5256e-01,  2.1080e-01, -1.9778e-01,\n",
              "          7.0343e-02, -3.1595e-01,  1.0277e-01,  3.7524e-01, -6.0235e-01,\n",
              "          6.9486e-02, -2.5931e-01,  1.8327e-01,  9.1877e-02,  2.4161e-01,\n",
              "         -1.1792e-02, -2.0682e-01,  3.0033e-02, -1.5018e-01,  1.8984e-01,\n",
              "         -1.7645e-01, -4.0443e-01, -3.6430e-02, -1.2943e-01, -7.8961e-02,\n",
              "         -3.5843e-01, -1.7917e-01,  7.4753e-02, -4.2492e-01,  1.3024e-01,\n",
              "         -1.6096e-01,  5.2433e-02,  1.7603e-01,  1.9840e-01, -1.6949e-01,\n",
              "          3.3143e-01,  1.5399e-01, -8.6765e-02,  8.6930e-02,  2.7660e-01,\n",
              "         -1.4490e-01, -4.3691e-01, -3.2205e-01,  4.1173e-01,  8.0560e-02,\n",
              "          5.8198e-02, -2.5824e-02,  1.7400e-01, -1.3320e-01,  1.8450e-01,\n",
              "          2.1292e-01,  1.2237e-02, -3.1975e-01, -3.7668e-01, -9.3971e-02,\n",
              "          1.9905e-01,  2.5165e-01,  2.2615e-01, -4.1726e-01,  1.6058e-01,\n",
              "         -2.5594e-01, -4.4263e-01,  2.0363e-02, -6.4844e-02, -2.9871e-01,\n",
              "          2.9571e-01, -8.0313e-02,  3.4145e-01,  3.7778e-02, -3.1723e-01,\n",
              "         -4.5565e-01, -5.1969e-01,  5.9634e-02,  1.8041e-01,  3.4179e-02,\n",
              "         -3.4609e-01, -4.7443e-02, -1.1472e-01,  5.3146e-01, -6.2839e-02,\n",
              "         -4.2871e-01, -9.8765e-02, -1.9524e-01,  4.1238e-01, -2.4986e-01,\n",
              "          2.4002e-01, -4.2261e-01, -9.0310e-02,  1.7113e-01,  4.8384e-01,\n",
              "         -3.8662e-02, -4.6448e-01, -4.0865e-01,  1.5564e-01,  3.3359e-02,\n",
              "          2.3412e-01,  2.8894e-01, -1.2402e-01, -2.0106e-01, -1.2766e-01,\n",
              "         -2.1626e-01,  5.1256e-01,  1.2014e-01, -5.2779e-01,  1.1061e-01,\n",
              "          1.4572e-01,  1.0273e-01, -1.4900e-01,  1.4837e-01,  1.5747e-01,\n",
              "          5.0256e-01, -1.3981e-01,  2.4960e-01, -2.1556e-01,  1.8051e-01,\n",
              "         -1.7574e-02, -2.1924e-01,  5.8594e-01,  2.4490e-01,  3.4241e-01,\n",
              "          2.1252e-01, -1.1878e-01,  3.6148e-01,  2.5502e-01, -2.0590e-01,\n",
              "         -9.9546e-02, -1.5726e-01,  2.1370e-02,  1.6508e-01,  1.4767e-01,\n",
              "          2.9560e-02,  1.9351e-02, -2.5248e-01, -3.5410e-01,  1.1197e-01,\n",
              "          1.4312e-01, -2.2335e-01,  2.1288e-01, -9.4496e-02,  1.5348e-01,\n",
              "          3.7114e-01, -6.4520e-02, -1.0227e-01,  3.5175e-01,  3.1452e-01,\n",
              "          2.8478e-02, -6.6053e-02, -3.6751e-01, -4.6537e-01,  9.1314e-02,\n",
              "          1.8053e-01,  8.1697e-02,  2.2173e-01, -1.5052e-01, -2.7990e-02,\n",
              "          6.3574e-02,  3.1708e-02,  3.2344e-01,  4.0189e-01, -1.1730e-01,\n",
              "          6.7051e-02, -6.2786e-01,  1.6876e-01,  2.5569e-02, -3.0410e-01,\n",
              "         -6.3565e-01,  3.4080e-02,  2.5083e-01, -1.8422e-01, -2.4557e-01,\n",
              "          2.9011e-01, -6.6308e-02,  4.3419e-02, -8.3300e-02,  1.5415e-01,\n",
              "          4.0475e-01,  9.1855e-02, -3.0362e-01,  3.3319e-01, -2.1789e-01,\n",
              "         -1.5026e-02, -4.3369e-03,  2.0172e-01,  2.9074e-02,  1.3452e-01,\n",
              "          3.6757e-01, -3.0576e-02, -1.1632e-01, -5.5705e-02, -8.7808e-02,\n",
              "          3.2806e-01,  1.5237e-01,  2.3776e-01,  4.8709e-02,  9.5313e-02,\n",
              "          8.8094e-02,  3.3715e-01, -3.9147e-01, -1.5379e-01,  9.2997e-02,\n",
              "          3.3999e-01,  1.3790e-02, -1.1771e-01,  3.0170e-01, -2.5120e-02,\n",
              "          2.3830e-01, -4.6540e-02, -3.1629e-01,  6.0986e-02, -3.5797e-01,\n",
              "         -2.8126e-01, -1.5130e-01,  1.3736e-02, -2.4588e-03,  3.5156e-01,\n",
              "         -2.2475e-01,  2.6321e-01, -8.7533e-02, -1.4229e-02, -1.6912e-01,\n",
              "          3.7108e-01, -2.7659e-01,  2.3112e-01,  3.2566e-01,  4.4284e-02,\n",
              "         -1.3376e-01, -1.1987e-01,  2.5420e-01,  1.6081e-01, -5.4576e-01,\n",
              "          1.0265e-01,  1.4852e-02,  5.1905e-02, -9.1265e-02,  3.2063e-01,\n",
              "          7.9518e-02,  3.1009e-01, -3.2473e-02, -5.8070e-02,  2.2864e-01,\n",
              "          7.2042e-02,  1.9695e-01, -4.8435e-02,  1.4026e-01,  3.3704e-01,\n",
              "         -4.1060e-01,  5.6829e-01,  6.5838e-03, -6.8751e-02,  5.5285e-01,\n",
              "         -7.3334e-02, -2.2651e-01, -3.2202e-01,  3.1355e-01,  3.6852e-02,\n",
              "         -8.1382e-02, -2.4501e-01,  2.5029e-01, -2.5251e-01]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(rnn_model.parameters(),lr = 0.001)"
      ],
      "metadata": {
        "id": "prKxpGTskum_"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## training model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for question,answer in dataloader:\n",
        "    outputs = rnn_model(question)\n",
        "    loss = criterion(outputs,answer[0])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss += loss.item()\n",
        "  print(f\"Epoch:{epoch+1},loss:{total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVqnEeBElFLf",
        "outputId": "ccb21beb-78c4-41fb-fd44-a8a68ceedd8f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1,loss:63.4034\n",
            "Epoch:2,loss:50.2389\n",
            "Epoch:3,loss:40.3892\n",
            "Epoch:4,loss:32.7829\n",
            "Epoch:5,loss:27.0603\n",
            "Epoch:6,loss:22.8494\n",
            "Epoch:7,loss:19.3895\n",
            "Epoch:8,loss:16.4901\n",
            "Epoch:9,loss:14.2019\n",
            "Epoch:10,loss:12.3678\n",
            "Epoch:11,loss:10.8132\n",
            "Epoch:12,loss:9.4169\n",
            "Epoch:13,loss:8.4252\n",
            "Epoch:14,loss:7.4405\n",
            "Epoch:15,loss:6.6519\n",
            "Epoch:16,loss:5.9610\n",
            "Epoch:17,loss:5.3313\n",
            "Epoch:18,loss:4.8502\n",
            "Epoch:19,loss:4.4120\n",
            "Epoch:20,loss:4.0360\n",
            "Epoch:21,loss:3.7022\n",
            "Epoch:22,loss:3.3868\n",
            "Epoch:23,loss:3.1164\n",
            "Epoch:24,loss:2.8763\n",
            "Epoch:25,loss:2.6693\n",
            "Epoch:26,loss:2.4729\n",
            "Epoch:27,loss:2.2932\n",
            "Epoch:28,loss:2.1400\n",
            "Epoch:29,loss:1.9992\n",
            "Epoch:30,loss:1.8608\n",
            "Epoch:31,loss:1.7403\n",
            "Epoch:32,loss:1.6281\n",
            "Epoch:33,loss:1.5305\n",
            "Epoch:34,loss:1.4341\n",
            "Epoch:35,loss:1.3462\n",
            "Epoch:36,loss:1.2653\n",
            "Epoch:37,loss:1.1883\n",
            "Epoch:38,loss:1.1213\n",
            "Epoch:39,loss:1.0575\n",
            "Epoch:40,loss:0.9976\n",
            "Epoch:41,loss:0.9417\n",
            "Epoch:42,loss:0.8897\n",
            "Epoch:43,loss:0.8407\n",
            "Epoch:44,loss:0.7945\n",
            "Epoch:45,loss:0.7517\n",
            "Epoch:46,loss:0.7114\n",
            "Epoch:47,loss:0.6731\n",
            "Epoch:48,loss:0.6387\n",
            "Epoch:49,loss:0.6048\n",
            "Epoch:50,loss:0.5735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model(torch.tensor(tokenize_index(\"what is the captial of france\",vocab))).unsq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMtyAk6el576",
        "outputId": "1a3365c3-0038-4ea6-e71a-0b58b344b62b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([324])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_answer(model,question,threshold=0.5):\n",
        "  tokenized_question = tokenize_index(question,vocab)\n",
        "  question_tensor = torch.tensor(tokenized_question).unsqueeze(0)\n",
        "  output = rnn_model(question_tensor)\n",
        "  probs = torch.nn.functional.softmax(output)\n",
        "  value,index = torch.max(probs,dim=1)\n",
        "  if value<threshold:\n",
        "    print(f\"I don't know\")\n",
        "  else:\n",
        "    print(list(vocab.keys())[index])\n"
      ],
      "metadata": {
        "id": "gm63PmLTpfHx"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_answer(rnn_model, \"What is the largest planet in our solar system?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eoy_1k_arEe4",
        "outputId": "b9968ba1-99f1-4c6d-bb66-385dde120815"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jupiter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3671193018.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  probs = torch.nn.functional.softmax(output)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_answer(rnn_model, \"What is the capital of Spain?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4PwaZ4irPKA",
        "outputId": "d08e196b-cd70-460d-9f53-c73d299a1f0b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "madrid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3671193018.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  probs = torch.nn.functional.softmax(output)\n"
          ]
        }
      ]
    }
  ]
}